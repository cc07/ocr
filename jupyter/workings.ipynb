{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = json.load(open('../data/label.json', 'r'))\n",
    "labels = [labels[str(idx)] for idx in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '../data/images'\n",
    "\n",
    "images = []\n",
    "# for f in listdir(img_path):\n",
    "#     if isfile(join(img_path, f)):\n",
    "for f in labels:\n",
    "    img_name = labels[str(f)]['label']\n",
    "    img = cv2.imread('{}/{}_{}.jpg'.format(img_path, f, img_name), cv2.IMREAD_GRAYSCALE)\n",
    "#         img = cv2.imread(join(img_path, f), cv2.IMREAD_GRAYSCALE)\n",
    "#         plt.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "    images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sparse(batch_size, images, labels, dtype=np.int64):\n",
    "    indices = []\n",
    "    values = []\n",
    "#     seq_length = []\n",
    "    \n",
    "    sample_index = np.random.choice(len(images) - 1, size=batch_size)\n",
    "    sample_images = []\n",
    "    \n",
    "    x_max = 0\n",
    "    y_max = 0\n",
    "\n",
    "    for key, index in zip(sample_index, range(batch_size)):\n",
    "        sample = labels[key]\n",
    "        length = sample['length']\n",
    "        label = sample['label']\n",
    "        \n",
    "        img = images[key]\n",
    "#         plt.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "        x_max = max(x_max, img.shape[0])\n",
    "        y_max = max(y_max, img.shape[1])\n",
    "\n",
    "#         seq_length.append(length)\n",
    "        sample_images.append(img)\n",
    "\n",
    "        for number, number_index in zip(label, range(length)):\n",
    "            indices.append((index, number_index))\n",
    "            values.append(ord(str(number)))\n",
    "\n",
    "    indices = np.array(indices, dtype=np.int64)\n",
    "    values = np.array(values, dtype=dtype)\n",
    "    shape = np.array([batch_size, np.asarray(indices).max(0)[1] + 1], dtype=np.int64)\n",
    "    seq_length = np.ones(batch_size) * np.asarray(indices).max(0)[1] + 1\n",
    "#     shape = np.array([batch_size, seq_length], np.int64)\n",
    "\n",
    "    return indices, values, shape, sample_images, seq_length, x_max, y_max\n",
    "\n",
    "# create_sparse(n_batch_size, images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_padding_to_images(x_max, y_max, images):\n",
    "\n",
    "    output = []\n",
    "    for img in images:\n",
    "        left_pad = int((x_max - img.shape[0]) / 2)\n",
    "        right_pad = x_max - img.shape[0] - int((x_max - img.shape[0]) / 2)\n",
    "        top_pad = int((y_max - img.shape[1]) / 2)\n",
    "        bottom_pad = y_max - img.shape[1] - int((y_max - img.shape[1]) / 2)\n",
    "\n",
    "        img = np.pad(img, \n",
    "                     pad_width=((left_pad, right_pad), \n",
    "                                (top_pad, bottom_pad)), \n",
    "                     mode='constant', \n",
    "                     constant_values=0)\n",
    "        \n",
    "        img = np.transpose(img.reshape((x_max, y_max)))\n",
    "        output.append(img)\n",
    "        \n",
    "    return np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1299a7da0>"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEUAAAD8CAYAAAAhSGmUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12657c7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample_images[0], cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batch_size = 32\n",
    "n_features = 32\n",
    "n_rnn_layers = 2\n",
    "n_hidden = 64\n",
    "n_classes = ord('z') - ord('a') + 10 + 1 + 1 + 1\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test_size = 0.3\n",
    "n_test_index = int(len(images) * n_test_size)\n",
    "\n",
    "train_images = images[:n_test_index]\n",
    "test_images = images[n_test_index:]\n",
    "\n",
    "train_labels = labels[:n_test_index]\n",
    "test_labels = labels[n_test_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    inputs = tf.placeholder(tf.float32, [None, None, n_features])\n",
    "    targets = tf.sparse_placeholder(tf.int32)\n",
    "    seq_len = tf.placeholder(tf.int32, [None])\n",
    "    \n",
    "    cells = []\n",
    "    for _ in range(n_rnn_layers):\n",
    "        cell = tf.contrib.rnn.LSTMCell(n_hidden)\n",
    "        cells.append(cell)\n",
    "        \n",
    "    stack = tf.contrib.rnn.MultiRNNCell(cells)\n",
    "\n",
    "    outputs, _ = tf.nn.dynamic_rnn(stack, inputs, seq_len, dtype=tf.float32)\n",
    "    \n",
    "    outputs = tf.reshape(outputs, [-1, n_hidden])\n",
    "    \n",
    "    W = tf.Variable(tf.truncated_normal([n_hidden,\n",
    "                                         n_classes],\n",
    "                                        stddev=0.1))\n",
    "    b = tf.Variable(tf.constant(0., shape=[n_classes]))\n",
    "    \n",
    "    logits = tf.matmul(outputs, W) + b\n",
    "    logits = tf.reshape(logits, [n_batch_size, -1, n_classes])\n",
    "    logits = tf.transpose(logits, (1, 0, 2))\n",
    "    \n",
    "    loss = tf.nn.ctc_loss(labels=targets, inputs=logits, sequence_length=seq_len)\n",
    "    cost = tf.reduce_mean(loss)\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate,\n",
    "                                           0.9).minimize(cost)\n",
    "    \n",
    "#     decoded, log_prob = tf.nn.ctc_greedy_decoder(logits, seq_len)\n",
    "    decoded, log_prob = tf.nn.ctc_beam_search_decoder(logits, seq_len, merge_repeated=False)\n",
    "    \n",
    "    ler = tf.reduce_mean(tf.edit_distance(tf.cast(decoded[0], tf.int32),\n",
    "                                          targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train_cost: 1737.506, train_ler: 32.700, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 1, train_cost: 1969.367, train_ler: 32.833, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 2, train_cost: 1615.827, train_ler: 33.900, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 3, train_cost: 1611.220, train_ler: 32.900, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 4, train_cost: 1819.304, train_ler: 32.900, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 5, train_cost: 1690.739, train_ler: 33.000, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 6, train_cost: 1705.490, train_ler: 33.900, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 7, train_cost: 2143.520, train_ler: 32.917, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 8, train_cost: 1781.228, train_ler: 33.700, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 9, train_cost: 1768.645, train_ler: 32.900, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 10, train_cost: 1530.641, train_ler: 32.400, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 11, train_cost: 1520.222, train_ler: 32.000, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 12, train_cost: 1821.038, train_ler: 33.650, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 13, train_cost: 1356.595, train_ler: 32.000, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 14, train_cost: 1327.787, train_ler: 32.250, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 15, train_cost: 1512.645, train_ler: 32.000, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 16, train_cost: 1597.814, train_ler: 33.167, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 17, train_cost: 1444.451, train_ler: 32.000, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 18, train_cost: 1429.713, train_ler: 32.000, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 19, train_cost: 1227.378, train_ler: 32.333, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 20, train_cost: 1185.387, train_ler: 32.000, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 21, train_cost: 990.618, train_ler: 32.000, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 22, train_cost: 966.441, train_ler: 32.000, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 23, train_cost: 876.147, train_ler: 32.000, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 24, train_cost: 813.530, train_ler: 32.000, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 25, train_cost: 771.830, train_ler: 32.000, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 26, train_cost: 689.891, train_ler: 32.000, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 27, train_cost: 635.042, train_ler: 32.000, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 28, train_cost: 590.561, train_ler: 32.000, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 29, train_cost: 546.829, train_ler: 32.000, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 30, train_cost: 507.005, train_ler: 32.000, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 31, train_cost: 473.283, train_ler: 32.000, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 32, train_cost: 451.635, train_ler: 32.000, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 33, train_cost: 424.366, train_ler: 32.000, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 34, train_cost: 409.413, train_ler: 32.000, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 35, train_cost: 383.676, train_ler: 32.000, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 36, train_cost: 370.893, train_ler: 32.000, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 37, train_cost: 358.078, train_ler: 32.000, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 38, train_cost: 341.880, train_ler: 32.000, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 39, train_cost: 332.980, train_ler: 32.000, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 40, train_cost: 322.986, train_ler: 32.000, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 41, train_cost: 306.775, train_ler: 32.000, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 42, train_cost: 303.976, train_ler: 32.000, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 43, train_cost: 295.063, train_ler: 32.000, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 44, train_cost: 287.442, train_ler: 32.000, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 45, train_cost: 279.979, train_ler: 32.000, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 46, train_cost: 273.838, train_ler: 32.000, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 47, train_cost: 267.737, train_ler: 32.000, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 48, train_cost: 262.848, train_ler: 32.000, val_cost: 0.000, val_ler: 0.000\n",
      "Epoch 49, train_cost: 256.935, train_ler: 32.000, val_cost: 0.000, val_ler: 0.000\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(50):\n",
    "        train_cost = train_ler = 0\n",
    "        \n",
    "        indices, values, shape, sample_images, seq_length, x_max, y_max = create_sparse(n_batch_size, train_images, train_labels)\n",
    "        sample_images = add_padding_to_images(x_max, y_max, sample_images)\n",
    "#         sample_images = np.transpose(sample_images, (0, 2, 1))\n",
    "        train_targets = tf.SparseTensorValue(indices=indices, values=values, dense_shape=shape)\n",
    "            \n",
    "        feed = {\n",
    "            inputs: sample_images,\n",
    "            targets: train_targets,\n",
    "            seq_len: seq_length,\n",
    "        }\n",
    "        \n",
    "        batch_cost, _ = sess.run([cost, optimizer], feed_dict=feed)\n",
    "        train_cost += batch_cost * n_batch_size\n",
    "        train_ler += sess.run(ler, feed_dict=feed) * n_batch_size\n",
    "        \n",
    "        log = 'Epoch {}, train_cost: {:.3f}, train_ler: {:.3f}, val_cost: {:.3f}, val_ler: {:.3f}'\n",
    "        print(log.format(epoch, train_cost, train_ler, 0, 0))\n",
    "        \n",
    "    decoded_values = sess.run(decoded[0], feed_dict=feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_decoded = ''.join([chr(x) for x in np.asarray(decoded_values[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x17\\x17\\x17\\x17\\x17\\x17\\x17\\x17\\x17\\x17\\x17\\x17\\x17\\x17\\x17\\x17\\x17\\x17\\x17\\x17\\x17\\x17\\x17\\x17\\x17\\x17\\x17\\x17\\x17\\x17\\x17'"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
       "       23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23])"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([83, 53, 50, 51, 53, 53, 48, 49, 51, 53, 48, 52, 50, 49, 48, 48, 52,\n",
       "       54, 57, 48, 55, 49, 48, 52, 52, 48, 53, 48, 49, 48, 51, 56, 49, 49,\n",
       "       51, 48, 49, 56, 49, 48, 57, 53, 53, 49, 48, 52, 56, 53, 51, 49, 50,\n",
       "       57, 49, 57, 53, 48, 66, 49, 50, 50, 57, 53, 53, 52, 57, 49, 49, 48,\n",
       "       53, 52, 57, 52, 53, 56, 53, 48, 49, 48, 55, 57, 51, 49, 51, 48, 52,\n",
       "       53, 51, 49, 53, 53, 52, 54, 53, 49, 57, 48, 57, 49, 53, 52, 56, 53,\n",
       "       49, 51, 53, 45, 56, 49, 51, 52, 53, 48, 57, 48, 55, 48, 48, 48, 53,\n",
       "       51, 49, 57, 49, 52, 57, 48, 55, 51, 56, 48, 51, 57, 52, 53, 48, 48,\n",
       "       53, 54, 51, 49, 56, 48, 49, 53, 45, 49, 50, 57, 52, 57, 48, 55, 50,\n",
       "       53, 49, 48, 51, 48, 57, 48, 55, 52, 57, 49, 53, 48, 48, 57, 51, 49,\n",
       "       49, 74, 49, 48, 52, 53, 48, 57, 52, 53, 57, 51, 49, 49, 53, 53, 49,\n",
       "       53, 55, 48, 48, 52, 53, 57, 51, 52, 49, 49, 53, 53, 57, 48, 55, 54,\n",
       "       51, 49, 48, 48, 54, 48, 51, 53, 52, 55, 57, 52, 49, 52, 66, 49, 50,\n",
       "       50, 57, 53, 53, 48, 53, 51, 49, 53, 48, 49, 49, 49, 52, 53, 57, 53,\n",
       "       52, 51, 49, 53, 49, 49, 49, 53, 57, 48, 50, 49, 52, 57, 51, 39, 52,\n",
       "       49, 51, 53, 52, 51, 49, 49, 49, 53, 57, 51, 50, 48, 48, 48, 49, 50,\n",
       "       49, 53, 51, 48, 54, 49, 57, 52, 49, 48, 49, 49, 49, 51, 52, 53, 52,\n",
       "       50, 54, 49, 53, 52, 53, 48, 51, 57, 49, 49, 50, 49, 48, 48, 52, 54,\n",
       "       57, 48])"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
